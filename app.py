import streamlit as st
import google.generativeai as genai
import replicate
import json
import os

# ================= é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="AI å¯¼æ¼”ç³»ç»Ÿ v5.1",
    page_icon="ğŸ¬",
    layout="wide"
)

# ================= ä¾§è¾¹æ  =================
with st.sidebar:
    st.header("ğŸ”‘ å¯åŠ¨é’¥åŒ™")

    google_key = st.secrets.get("GOOGLE_API_KEY") or st.text_input(
        "Google API Key", type="password"
    )
    replicate_key = st.secrets.get("REPLICATE_API_TOKEN") or st.text_input(
        "Replicate API Token", type="password"
    )

    st.markdown("---")
    if st.button("ğŸ—‘ï¸ æ¸…é™¤å†å²è®°å¿†"):
        st.session_state.messages = []
        st.rerun()

# ================= VCC å†…æ ¸ =================
VCC_KERNEL = """
You are the Visual Continuity Compiler (VCC) v5.1.
You are NOT a chatbot.
You output STRICT JSON ONLY.

IMMUTABLE CONSTANTS:
ACTOR: a young girl in a red hanfu, twin ponytails with red ribbons, black hair
SET: interior of a massive ancient CIRCULAR Tulou building, rainy afternoon, mist,
     neat rows of red paper lanterns hanging along the curved wooden corridors
COLOR: dominant red lantern glow, warm interior lights vs cool blue rainy exterior
NEGATIVE: (text:2.0), (watermark:2.0), (logo:2.0), bad anatomy, extra limbs

STYLE DEFAULT: Ghibli
CAMERA DEFAULT: medium shot

OUTPUT FORMAT:
{
  "meta": {
    "user_language": "CN or EN",
    "style_state": { "id": 1, "name": "Ghibli" }
  },
  "director_log": "string",
  "prompt_data": {
    "positive_prompt": "string",
    "negative_prompt": "string",
    "aspect_ratio": "16:9"
  }
}
"""

# ================= å¯¼æ¼”å¤§è„‘ =================
def get_director_response(user_input, history):
    if not google_key:
        st.error("âŒ ç¼ºå°‘ Google API Key")
        return None

    genai.configure(api_key=google_key)

    model = genai.GenerativeModel(
        model_name="models/gemini-3-pro-preview",
        system_instruction=VCC_KERNEL
    )

    chat = model.start_chat(history=[
        {
            "role": "user" if m["role"] == "user" else "model",
            "parts": [m["content"]]
        }
        for m in history
    ])

    response = chat.send_message(user_input)

    if not response.text:
        st.error("âŒ Gemini æ— è¿”å›å†…å®¹")
        return None

    try:
        text = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(text)
    except Exception as e:
        st.error("âŒ JSON è§£æå¤±è´¥")
        st.code(response.text)
        return None

# ================= å›¾åƒç”Ÿæˆï¼ˆå·²ä¿®å¤ï¼‰ =================
def generate_image(positive_prompt, negative_prompt):
    if not replicate_key:
        st.error("âŒ ç¼ºå°‘ Replicate API Token")
        return None

    os.environ["REPLICATE_API_TOKEN"] = replicate_key

    try:
        output = replicate.run(
            "black-forest-labs/flux-1.1",
            input={
                "prompt": positive_prompt,
                "negative_prompt": negative_prompt,
                "aspect_ratio": "16:9",
                "num_outputs": 1
            }
        )

        # âš ï¸ Replicate è¿”å›çš„æ˜¯ iterator
        for img in output:
            return img

    except Exception as e:
        st.error(f"âŒ ç»˜å›¾å¤±è´¥: {e}")
        return None

# ================= ä¸»ç•Œé¢ =================
st.title("ğŸ¬ AI å¯¼æ¼”ç³»ç»Ÿ (Visual Director)")
st.markdown("*å†…æ ¸ç‰ˆæœ¬: VCC v5.1 ï½œ æ¸²æŸ“å¼•æ“: FLUX 1.1*")

if "messages" not in st.session_state:
    st.session_state.messages = []

# å†å²æ¸²æŸ“
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        if msg["type"] == "text":
            st.markdown(msg["content"])
        elif msg["type"] == "image":
            st.image(msg["content"])
            with st.expander("æŸ¥çœ‹ Prompt"):
                st.code(msg["prompt_text"])

# ================= è¾“å…¥åŒº =================
if user_input := st.chat_input("è¾“å…¥æŒ‡ä»¤ï¼ˆä¾‹ï¼šé•œå¤´1ï¼Œå¥¹ç«™åœ¨é›¨ä¸­çš„åœŸæ¥¼ï¼‰"):
    # ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({
        "role": "user",
        "type": "text",
        "content": user_input
    })

    with st.chat_message("assistant"):
        with st.spinner("ğŸ§  å¯¼æ¼”æ­£åœ¨æ„æ€åˆ†é•œ..."):
            text_history = [m for m in st.session_state.messages if m["type"] == "text"]
            director = get_director_response(user_input, text_history)

        if director:
            log = f"**å¯¼æ¼”æ—¥å¿—ï¼š** {director['director_log']}\n\n" \
                  f"*é£æ ¼ï¼š{director['meta']['style_state']['name']}*"
            st.markdown(log)

            st.session_state.messages.append({
                "role": "assistant",
                "type": "text",
                "content": log
            })

            pos = director["prompt_data"]["positive_prompt"]
            neg = director["prompt_data"]["negative_prompt"]

            with st.spinner("ğŸ¨ æ­£åœ¨æ¸²æŸ“ç”»é¢..."):
                img_url = generate_image(pos, neg)

            if img_url:
                st.image(img_url)
                st.session_state.messages.append({
                    "role": "assistant",
                    "type": "image",
                    "content": img_url,
                    "prompt_text": pos
                })
